{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment III\n",
    "Aarya Doshi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aarya\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:260: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import codecs\n",
    "import json\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from sklearn import svm, metrics\n",
    "\n",
    "from scipy.sparse import hstack\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from torch.utils.data import DataLoader\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(path):\n",
    "  with codecs.open(path, 'r', 'utf-8') as myFile:\n",
    "    content = myFile.read()\n",
    "  dataset = json.loads(content)\n",
    "  return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average success rate is: 24.63%\n"
     ]
    }
   ],
   "source": [
    "path = 'data/pizza_request_dataset.json'\n",
    "dataset = read_dataset(path)\n",
    "\n",
    "successes = [r['requester_received_pizza'] for r in dataset]\n",
    "success_rate = 100.0 * sum(successes) / float(len(successes))\n",
    "print ('The average success rate is: %.2f%%' %(success_rate))\n",
    "\n",
    "indices = list(range(len(dataset)))\n",
    "train_idx, test_idx = train_test_split(\n",
    "    indices, test_size=567, random_state=23, stratify=successes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(text, keep_words=None):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    if keep_words:\n",
    "        stop_words -= keep_words\n",
    "\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text) # remove punc\n",
    "    words = re.findall(r'\\b\\w+\\b', text, re.IGNORECASE)\n",
    "\n",
    "    # # lemmatize and remove stopwords\n",
    "    clean = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
    "    return clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    svm_model = svm.SVC(kernel='linear', probability=False, random_state=23, class_weight=\"balanced\")\n",
    "    svm_model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = svm_model.predict(X_test)\n",
    "    y_score = svm_model.decision_function(X_test)\n",
    "\n",
    "    accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "    precision = metrics.precision_score(y_test, y_pred, zero_division=0)\n",
    "    recall = metrics.recall_score(y_test, y_pred, zero_division=0)\n",
    "    f1 = metrics.f1_score(y_test, y_pred, zero_division=0)\n",
    "    auc = metrics.roc_auc_score(y_test, y_score)\n",
    "\n",
    "    tn, fp, fn, tp = metrics.confusion_matrix(y_test, y_pred).ravel()\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
    "    \n",
    "    return accuracy, precision, recall, f1, specificity, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(accuracy, precision, recall, f1, specificity, auc):\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"Specificity: {specificity:.4f}\")\n",
    "    print(f\"AUC: {auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1 – n-grams\n",
    "<p> This model will extract the top 500 unigrams and top 500 bigrams as features to \n",
    "classify posts that would be successful or those that will be unsuccessful in their pizza requests.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_grams(X_train, X_test, n, count):\n",
    "    \n",
    "    # vectorizer = CountVectorizer(ngram_range=(n, n), stop_words='english', max_features=count)\n",
    "    vectorizer = TfidfVectorizer(ngram_range=(n, n), stop_words='english', max_features=count, sublinear_tf=True)\n",
    "    train_gram = vectorizer.fit_transform(X_train)\n",
    "    test_gram = vectorizer.transform(X_test)\n",
    "\n",
    "    # print top words\n",
    "    # word_counts = np.array(train_gram.sum(axis=0)).flatten()\n",
    "    # word_freq = dict(zip(vectorizer.get_feature_names_out(), word_counts))\n",
    "    # top_5_words = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)\n",
    "    # print(top_5_words)\n",
    "\n",
    "    return train_gram, test_gram\n",
    "\n",
    "def model_1():\n",
    "    \n",
    "    data = [f\"{r['request_title']} {r['request_text']}\" for r in dataset]\n",
    "    X_train = [data[i] for i in train_idx]\n",
    "    X_test = [data[i] for i in test_idx]\n",
    "    y_train = [successes[i] for i in train_idx]\n",
    "    y_test = [successes[i] for i in test_idx]\n",
    "\n",
    "    train_unigram, test_unigram = n_grams(X_train, X_test, 1, 500)\n",
    "    train_bigram, test_bigram = n_grams(X_train, X_test, 2, 500)\n",
    "\n",
    "    X_train_combined = hstack([train_unigram, train_bigram])\n",
    "    X_test_combined = hstack([test_unigram, test_bigram])\n",
    "\n",
    "    return X_train_combined, X_test_combined, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6155\n",
      "Precision: 0.3304\n",
      "Recall: 0.5429\n",
      "F1 Score: 0.4108\n",
      "Specificity: 0.6393\n",
      "AUC: 0.6192\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = model_1()\n",
    "acc, prec, rec, f1, spec, auc = train_and_evaluate(X_train, X_test, y_train, y_test)\n",
    "print_results(acc, prec, rec, f1, spec, auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2 – Activity and Reputation\n",
    "<p> This model will utilize a variety of the activity and reputation data included in the dataset file (pizza_request_dataset.json) as features to distinguish between successful and \n",
    "unsuccessful requests. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_2():\n",
    "    data = [[\n",
    "        1 if r['post_was_edited'] else 0,\n",
    "        np.log1p(r['requester_account_age_in_days_at_request']),\n",
    "        np.log1p(r['requester_account_age_in_days_at_retrieval']),\n",
    "        np.log1p(r['requester_days_since_first_post_on_raop_at_request']),\n",
    "        np.log1p(r['requester_days_since_first_post_on_raop_at_retrieval']),\n",
    "        np.log1p(r['requester_number_of_comments_at_request']),\n",
    "        np.log1p(r['requester_number_of_comments_at_retrieval']),\n",
    "        np.log1p(r['requester_number_of_comments_in_raop_at_request']),\n",
    "        np.log1p(r['requester_number_of_comments_in_raop_at_retrieval']),\n",
    "        np.log1p(r['requester_number_of_posts_at_request']),\n",
    "        np.log1p(r['requester_number_of_posts_at_retrieval']),\n",
    "        np.log1p(r['requester_number_of_posts_on_raop_at_request']),\n",
    "        np.log1p(r['requester_number_of_posts_on_raop_at_retrieval']),\n",
    "        np.log1p(r['requester_number_of_subreddits_at_request']),\n",
    "        np.log1p(len(r['requester_subreddits_at_request'])),\n",
    "        np.log1p(r['number_of_downvotes_of_request_at_retrieval']),\n",
    "        np.log1p(r['number_of_upvotes_of_request_at_retrieval']),\n",
    "        r['requester_upvotes_minus_downvotes_at_request'],\n",
    "        r['requester_upvotes_minus_downvotes_at_retrieval'],\n",
    "        np.log1p(r['requester_upvotes_plus_downvotes_at_request']),\n",
    "        np.log1p(r['requester_upvotes_plus_downvotes_at_retrieval'])\n",
    "        ]\n",
    "        for r in dataset\n",
    "    ]\n",
    "\n",
    "    X_train = [data[i] for i in train_idx]\n",
    "    X_test = [data[i] for i in test_idx]\n",
    "    y_train = [successes[i] for i in train_idx]\n",
    "    y_test = [successes[i] for i in test_idx]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    return X_train_scaled, X_test_scaled, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8166\n",
      "Precision: 0.6011\n",
      "Recall: 0.7643\n",
      "F1 Score: 0.6730\n",
      "Specificity: 0.8337\n",
      "AUC: 0.8789\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = model_2()\n",
    "acc, prec, rec, f1, spec, auc = train_and_evaluate(X_train, X_test, y_train, y_test)\n",
    "\n",
    "print_results(acc, prec, rec, f1, spec, auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3 – Narratives \n",
    "This third model will extract features corresponding to the narrative dimensions identified in [1]. Refer to the enclosed files within “/resources/narratives”. There are five narratives – desire, family, job, money, and student. Each narrative file has a set of words associated with it. To extract post features corresponding to a narrative, perform regular expression match between all words corresponding to the narrative and those corresponding to a post (in the training and test sets). The narrative features for a post will be the ratio of the number of matches for each narrative to the total number of white spaced words in the post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_3(scale_factor):\n",
    "    \n",
    "    narrative_words = {\n",
    "        'desire': set(codecs.open('resources/narratives/desire.txt', 'r', encoding='utf-8').read().strip().splitlines()),\n",
    "        'family': set(codecs.open('resources/narratives/family.txt', 'r', encoding='utf-8').read().strip().splitlines()),\n",
    "        'job': set(codecs.open('resources/narratives/job.txt', 'r', encoding='utf-8').read().strip().splitlines()),\n",
    "        'money': set(codecs.open('resources/narratives/money.txt', 'r', encoding='utf-8').read().strip().splitlines()),\n",
    "        'student': set(codecs.open('resources/narratives/student.txt', 'r', encoding='utf-8').read().strip().splitlines())\n",
    "    }    \n",
    "\n",
    "    all_narrative_words  = set().union(*narrative_words.values())\n",
    "    \n",
    "    data = []\n",
    "\n",
    "    for r in dataset:\n",
    "        text = f\"{r['request_title']} {r['request_text']}\".lower()\n",
    "        clean_words = clean_data(text, all_narrative_words)\n",
    "        total_words = len(clean_words)\n",
    "\n",
    "        features = [] \n",
    "        for narrative, words in narrative_words.items():\n",
    "            matched_words = [w for w in clean_words if w in words]\n",
    "            features.append(np.log1p(scale_factor * len(matched_words) / total_words if total_words > 0 else 0))\n",
    "\n",
    "        data.append(features)\n",
    "\n",
    "    X_train = [data[i] for i in train_idx]\n",
    "    X_test = [data[i] for i in test_idx]\n",
    "    y_train = [successes[i] for i in train_idx]\n",
    "    y_test = [successes[i] for i in test_idx]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5185\n",
      "Precision: 0.2915\n",
      "Recall: 0.6643\n",
      "F1 Score: 0.4052\n",
      "Specificity: 0.4707\n",
      "AUC: 0.5841\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = model_3(2)\n",
    "acc, prec, rec, f1, spec, auc = train_and_evaluate(X_train, X_test, y_train, y_test)\n",
    "\n",
    "print_results(acc, prec, rec, f1, spec, auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 4 - Moral Foundations\n",
    "This third model will use the dimensions of “moral foundations” as features for classifying successful and unsuccessful requests. These dimensions are based on the moral foundations theory that seeks to understand why morality varies so much across cultures yet still shows so many similarities and recurrent themes. In brief, the theory proposes that several innate and universally available psychological systems are the foundations of “intuitive ethics.” The dimensions of the moral foundations include: care/harm, fairness/cheating, loyalty/betrayal, authority/subversion, and sanctity/degradation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_4(scale_factor):\n",
    "    dimensions = {\n",
    "        'care/harm': set(),\n",
    "        'fairness/cheating': set(),\n",
    "        'loyalty/betrayal': set(),\n",
    "        'authority/subversion': set(),\n",
    "        'sanctity/degradation': set()\n",
    "    }\n",
    "\n",
    "    map = {\n",
    "        '01': 'care/harm', \n",
    "        '02': 'care/harm',\n",
    "        '03': 'fairness/cheating',\n",
    "        '04': 'fairness/cheating',\n",
    "        '05': 'loyalty/betrayal',\n",
    "        '06': 'loyalty/betrayal',\n",
    "        '07': 'authority/subversion',\n",
    "        '08': 'authority/subversion',\n",
    "        '09': 'sanctity/degradation',\n",
    "        '10': 'sanctity/degradation'\n",
    "    }\n",
    "\n",
    "    moral_words = set()\n",
    "\n",
    "    with open('resources/MoralFoundations.dic', 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            if line.strip() and not line.startswith('%'):\n",
    "                parts = re.split(r'\\s+', line.strip())\n",
    "                term, categories = parts[0], parts[1:]\n",
    "\n",
    "                for category in categories:\n",
    "                    if category in map:\n",
    "                        dimensions[map[category]].add(term)\n",
    "                        moral_words.add(term)\n",
    "    data = []\n",
    "\n",
    "    for r in dataset:\n",
    "        text = f\"{r['request_title']} {r['request_text']}\".lower()\n",
    "        clean_words = clean_data(text, moral_words)\n",
    "        total_words = len(clean_words)\n",
    "\n",
    "        features = []\n",
    "        for foundation, words in dimensions.items():\n",
    "            pattern = r'\\b(?:' + '|'.join(word.replace('*', r'\\w*') for word in words) + r')\\b'\n",
    "\n",
    "            matched_words = re.findall(pattern, text, re.IGNORECASE)\n",
    "            features.append(np.log1p(scale_factor * len(matched_words) / total_words if total_words > 0 else 0))\n",
    "\n",
    "        data.append(features)\n",
    "\n",
    "    X_train = [data[i] for i in train_idx]\n",
    "    X_test = [data[i] for i in test_idx]\n",
    "    y_train = [successes[i] for i in train_idx]\n",
    "    y_test = [successes[i] for i in test_idx]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6543\n",
      "Precision: 0.2879\n",
      "Recall: 0.2714\n",
      "F1 Score: 0.2794\n",
      "Specificity: 0.7799\n",
      "AUC: 0.5522\n"
     ]
    }
   ],
   "source": [
    "scale_factor = 1250\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_4(scale_factor)\n",
    "\n",
    "acc, prec, rec, f1, spec, auc = train_and_evaluate(X_train, X_test, y_train, y_test)\n",
    "print_results(acc, prec, rec, f1, spec, auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 5 - Pre-trained BERT\n",
    "For this model, I used the pretrained bert-base-uncased model to generate embeddings for each request post without any fine-tuning. I averaged the token-level embeddings from BERT to obtain a fixed-size vector for each post to train the linear SVM classifier on these vectors. This approach allows the model to capture deeper semantic and contextual information from the text, beyond keyword matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_5():\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    model = BertModel.from_pretrained('bert-base-uncased')\n",
    "    model.eval()\n",
    "\n",
    "    embeddings = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for r in dataset:\n",
    "            text = f\"{r['request_title']} {r['request_text']}\"\n",
    "            inputs = tokenizer(text, padding=True, truncation=True, max_length=512, return_tensors='pt')\n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "            token_embeddings = outputs.last_hidden_state.squeeze(0)\n",
    "            post_embedding = token_embeddings.mean(dim=0).numpy()\n",
    "            embeddings.append(post_embedding)\n",
    "    \n",
    "    data = np.array(embeddings)\n",
    "    y = np.array(successes)\n",
    "\n",
    "    X_train = data[train_idx]\n",
    "    X_test = data[test_idx]\n",
    "    y_train = y[train_idx]\n",
    "    y_test = y[test_idx]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6067\n",
      "Precision: 0.3398\n",
      "Recall: 0.6286\n",
      "F1 Score: 0.4411\n",
      "Specificity: 0.5995\n",
      "AUC: 0.6386\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = model_5()\n",
    "\n",
    "acc, prec, rec, f1, spec, auc = train_and_evaluate(X_train, X_test, y_train, y_test)\n",
    "print_results(acc, prec, rec, f1, spec, auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
